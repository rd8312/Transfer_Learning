{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using VGG pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a4022\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\a4022\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\a4022/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:59<00:00, 9.30MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# # Old weights with accuracy 76.130%\n",
    "# resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# # New weights with accuracy 80.858%\n",
    "# resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# # Best available weights (currently alias for IMAGENET1K_V2)\n",
    "# # Note that these weights may change across versions\n",
    "# resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# # Strings are also supported\n",
    "# resnet50(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "# # No weights - random initialization\n",
    "# resnet50(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns an iterator over immediate children modules, yielding both\n",
      "        the name of the module as well as the module itself.\n",
      "\n",
      "        Yields:\n",
      "            (str, Module): Tuple containing a name and child module\n",
      "\n",
      "        Example::\n",
      "\n",
      "            >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      "            >>> for name, module in model.named_children():\n",
      "            >>>     if name in ['conv4', 'conv5']:\n",
      "            >>>         print(module)\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(model.named_children.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children Counter:  0  Layer Name:  features\n",
      "Children Counter:  1  Layer Name:  avgpool\n",
      "Children Counter:  2  Layer Name:  classifier\n"
     ]
    }
   ],
   "source": [
    "children_counter = 0\n",
    "for n,c in model.named_children():\n",
    "    print(\"Children Counter: \",children_counter,\" Layer Name: \",n)\n",
    "    children_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show model detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No containing the name of module\n",
    "torch.nn.Sequential(*list(model.children())[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features', 'avgpool', 'classifier'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only show the \"features\" module\n",
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4096])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[-1].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[-1].out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.78\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 747.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 1000])\n",
      "torch.Size([1000])\n",
      "tensor([1.3414e-07, 1.6315e-07, 1.5266e-08, 3.5969e-08, 1.0951e-08, 5.2702e-07,\n",
      "        4.8206e-09, 1.9585e-06, 5.2911e-05, 2.1777e-07, 1.4539e-06, 1.2662e-06,\n",
      "        2.3480e-07, 3.0544e-07, 2.0742e-07, 5.9747e-07, 6.7474e-07, 4.0036e-06,\n",
      "        1.6504e-07, 8.5027e-08, 2.7182e-08, 1.3676e-06, 1.8212e-08, 2.3156e-07,\n",
      "        6.5007e-08, 1.4044e-07, 5.1115e-08, 2.4584e-08, 4.4783e-08, 8.6751e-08,\n",
      "        2.4636e-07, 1.0413e-07, 4.8620e-07, 2.1248e-08, 2.4500e-08, 1.3709e-07,\n",
      "        2.7730e-07, 1.2557e-07, 8.1565e-07, 7.1978e-07, 1.2952e-07, 1.0625e-07,\n",
      "        1.7708e-07, 8.3580e-07, 8.0771e-08, 2.1152e-07, 3.8485e-07, 4.2519e-07,\n",
      "        5.1045e-08, 2.6455e-08, 2.7786e-08, 8.3700e-07, 9.7426e-08, 4.4830e-08,\n",
      "        4.3400e-07, 1.0407e-07, 1.2046e-07, 6.9725e-08, 1.2719e-07, 2.9716e-07,\n",
      "        1.0842e-06, 9.2345e-08, 3.8705e-07, 2.2614e-06, 1.4269e-07, 7.6063e-08,\n",
      "        4.2889e-06, 1.9366e-07, 6.2561e-07, 6.0362e-08, 1.1159e-07, 5.8791e-08,\n",
      "        5.6303e-08, 1.3925e-07, 7.0501e-08, 2.1572e-08, 3.2634e-08, 7.7985e-08,\n",
      "        6.3632e-07, 3.3263e-07, 2.0213e-06, 1.2525e-07, 6.9830e-06, 1.4113e-05,\n",
      "        5.2529e-07, 7.7259e-07, 6.7025e-06, 1.5848e-08, 3.6557e-08, 3.3278e-07,\n",
      "        5.1068e-08, 1.5278e-07, 5.0905e-08, 8.0458e-08, 1.3069e-07, 1.3771e-08,\n",
      "        1.5546e-08, 1.5299e-07, 8.0236e-08, 2.1558e-07, 1.4448e-08, 1.2345e-08,\n",
      "        4.5546e-07, 2.4377e-07, 7.7936e-06, 2.7882e-07, 1.8260e-05, 3.1900e-08,\n",
      "        1.2475e-06, 2.3705e-07, 3.1053e-07, 1.7201e-07, 2.3234e-06, 2.7043e-06,\n",
      "        6.4882e-07, 1.6148e-06, 5.6305e-08, 5.3861e-06, 4.1439e-08, 8.6531e-09,\n",
      "        2.1155e-09, 7.6841e-09, 1.1745e-08, 8.9340e-09, 7.1975e-08, 1.8896e-08,\n",
      "        1.1153e-07, 8.8803e-09, 3.8913e-09, 5.5188e-09, 1.8390e-08, 3.1184e-09,\n",
      "        2.6351e-08, 6.0095e-07, 1.5746e-08, 6.4705e-08, 7.6575e-08, 2.3655e-08,\n",
      "        4.5818e-07, 2.9858e-08, 3.1071e-08, 2.5515e-08, 4.1845e-08, 2.8459e-08,\n",
      "        7.0985e-09, 5.0367e-07, 3.8564e-08, 4.7699e-09, 2.3834e-08, 2.1854e-08,\n",
      "        1.3636e-06, 3.0752e-03, 9.9286e-05, 9.5896e-07, 1.7447e-04, 6.2433e-06,\n",
      "        8.5223e-06, 8.3057e-05, 3.6815e-05, 2.1526e-06, 4.5317e-06, 7.3892e-07,\n",
      "        8.9205e-07, 4.4736e-06, 5.7386e-08, 1.0726e-07, 7.0171e-08, 1.4789e-07,\n",
      "        1.5475e-05, 1.9990e-07, 8.1921e-08, 1.8114e-06, 2.2187e-07, 3.2196e-05,\n",
      "        1.1177e-05, 3.9265e-07, 4.3843e-07, 7.8968e-09, 3.0421e-07, 8.6038e-07,\n",
      "        1.2820e-06, 3.8772e-08, 2.4247e-06, 9.2445e-08, 2.1041e-06, 6.5963e-05,\n",
      "        1.7607e-03, 4.9733e-05, 3.3474e-06, 5.8892e-06, 1.0248e-06, 1.2256e-06,\n",
      "        6.5561e-06, 1.0028e-04, 2.8001e-06, 1.3410e-05, 8.6789e-07, 3.0724e-07,\n",
      "        3.7694e-07, 4.2079e-06, 1.7765e-05, 6.0085e-06, 4.0855e-06, 8.2721e-06,\n",
      "        4.0131e-06, 3.1479e-07, 4.3739e-08, 1.6673e-04, 1.0550e-05, 1.2758e-06,\n",
      "        1.7376e-08, 1.5890e-06, 2.6031e-07, 1.9008e-06, 2.3902e-07, 2.6651e-06,\n",
      "        4.3613e-06, 6.0331e-07, 9.7169e-06, 1.4111e-05, 1.7030e-05, 4.0372e-08,\n",
      "        2.0272e-06, 1.1237e-05, 1.4311e-06, 3.6296e-05, 1.3233e-06, 7.9995e-05,\n",
      "        7.6229e-08, 5.0580e-07, 1.2670e-05, 9.4487e-05, 1.3457e-05, 1.8793e-07,\n",
      "        2.0457e-06, 4.1829e-05, 8.1672e-07, 8.9001e-06, 5.5947e-06, 1.9430e-06,\n",
      "        1.0823e-05, 1.3584e-06, 1.6555e-06, 4.5273e-06, 3.2843e-06, 1.2230e-04,\n",
      "        5.4359e-07, 4.6240e-06, 3.6132e-04, 3.3498e-05, 1.2346e-04, 1.2654e-06,\n",
      "        8.8377e-07, 1.5089e-04, 4.1819e-06, 3.0847e-06, 8.9337e-07, 1.9123e-06,\n",
      "        1.4011e-05, 5.9746e-04, 3.6104e-04, 8.9863e-06, 2.8259e-04, 4.5178e-03,\n",
      "        1.9424e-03, 2.0310e-06, 7.5310e-07, 1.2165e-07, 8.9510e-07, 9.5545e-06,\n",
      "        3.1021e-05, 1.7296e-05, 7.8871e-06, 4.1764e-04, 5.0946e-04, 2.8049e-06,\n",
      "        1.5233e-05, 1.2250e-03, 1.2093e-03, 9.7089e-05, 2.1793e-04, 1.6366e-01,\n",
      "        1.5827e-01, 2.0361e-02, 7.8134e-03, 6.0676e-01, 8.7146e-04, 1.1653e-02,\n",
      "        4.7916e-05, 3.6473e-06, 1.2939e-04, 2.1225e-04, 2.4772e-03, 2.1883e-05,\n",
      "        2.7458e-06, 3.1096e-07, 1.7420e-06, 4.3776e-08, 1.7682e-05, 2.0289e-05,\n",
      "        1.5418e-08, 5.9185e-08, 5.4427e-09, 1.1454e-08, 4.2397e-08, 5.9547e-09,\n",
      "        2.4374e-08, 5.2176e-09, 1.9440e-08, 2.2160e-07, 4.5210e-08, 1.0629e-07,\n",
      "        2.1542e-07, 3.6183e-08, 9.1481e-08, 2.8680e-08, 9.8372e-08, 3.6466e-08,\n",
      "        9.4216e-08, 3.0978e-08, 9.2366e-09, 1.8437e-07, 2.6508e-06, 6.5979e-08,\n",
      "        9.2923e-08, 2.5534e-07, 5.2264e-07, 3.4016e-07, 8.3702e-08, 2.8056e-08,\n",
      "        2.0534e-04, 1.0517e-03, 1.9635e-04, 1.3370e-04, 6.5295e-07, 5.6049e-04,\n",
      "        4.5967e-06, 7.3776e-06, 2.1356e-05, 4.0308e-06, 1.5070e-05, 1.3418e-06,\n",
      "        8.6524e-07, 2.9213e-07, 3.2870e-07, 2.2137e-07, 1.7691e-08, 7.4060e-08,\n",
      "        1.0808e-07, 2.9307e-07, 9.5533e-07, 1.3195e-06, 7.8642e-06, 2.5208e-05,\n",
      "        4.8223e-07, 1.2448e-05, 1.0142e-03, 7.4547e-05, 3.4632e-05, 5.2422e-05,\n",
      "        1.0103e-05, 4.9878e-06, 3.1779e-06, 7.2033e-07, 2.5087e-07, 1.0243e-06,\n",
      "        5.5194e-08, 5.2136e-07, 1.3900e-05, 3.0037e-07, 4.9755e-06, 1.3532e-05,\n",
      "        1.8336e-07, 6.4214e-05, 4.2713e-06, 8.3809e-08, 1.1018e-06, 3.3564e-06,\n",
      "        2.0940e-06, 3.0055e-07, 3.3410e-06, 9.8695e-07, 3.7552e-06, 8.5073e-06,\n",
      "        2.6880e-05, 5.8450e-08, 4.7166e-08, 9.4227e-06, 3.9719e-07, 5.5490e-08,\n",
      "        1.5719e-08, 4.2435e-08, 1.2942e-07, 3.0630e-08, 3.9354e-08, 3.7226e-08,\n",
      "        1.9501e-08, 1.3049e-07, 8.4813e-07, 4.7015e-07, 2.4101e-07, 1.9770e-07,\n",
      "        9.0171e-07, 1.5652e-08, 4.1709e-08, 2.7890e-08, 4.2133e-07, 8.5058e-09,\n",
      "        4.2303e-07, 2.0393e-06, 5.4621e-08, 3.2711e-07, 5.2176e-05, 3.5115e-08,\n",
      "        1.2115e-06, 2.0299e-06, 1.5115e-07, 2.2402e-06, 9.8939e-07, 9.0612e-06,\n",
      "        4.2478e-07, 3.8815e-07, 2.7085e-07, 4.0896e-08, 3.4891e-08, 4.2369e-08,\n",
      "        1.2195e-06, 5.6572e-05, 9.1440e-06, 1.0435e-05, 1.2148e-07, 1.0512e-06,\n",
      "        7.1551e-08, 4.2573e-07, 8.9693e-06, 7.1591e-06, 2.9937e-08, 6.2303e-07,\n",
      "        5.6999e-06, 3.7434e-06, 2.5539e-06, 4.9041e-07, 6.0162e-07, 9.2571e-07,\n",
      "        3.0810e-08, 4.3230e-07, 1.9114e-06, 5.6889e-07, 2.2852e-07, 1.9839e-08,\n",
      "        2.0035e-08, 2.8126e-07, 4.3992e-07, 8.7906e-06, 1.1956e-06, 4.8843e-06,\n",
      "        1.8654e-07, 6.1413e-05, 7.9470e-08, 1.4535e-07, 3.2461e-07, 2.5698e-07,\n",
      "        8.2292e-06, 3.1446e-04, 8.6223e-07, 5.4053e-07, 9.8328e-09, 1.1195e-08,\n",
      "        9.0244e-08, 2.3254e-05, 1.4093e-04, 4.9809e-08, 3.0890e-07, 1.1854e-06,\n",
      "        1.4058e-07, 1.1725e-07, 3.6313e-07, 3.0974e-07, 1.7707e-04, 6.9182e-07,\n",
      "        6.5168e-08, 1.9067e-07, 1.2496e-07, 1.1901e-07, 3.4596e-07, 1.6869e-07,\n",
      "        2.5080e-08, 1.7082e-06, 1.2675e-06, 8.9641e-07, 8.7521e-08, 2.8717e-07,\n",
      "        1.5929e-06, 8.4682e-06, 2.4373e-07, 2.6844e-07, 4.8258e-07, 5.5940e-07,\n",
      "        2.3010e-07, 3.4927e-07, 3.5133e-08, 9.6807e-07, 1.7570e-06, 5.3290e-06,\n",
      "        4.5963e-06, 7.3953e-07, 5.3175e-06, 5.7540e-07, 1.2212e-05, 3.0342e-07,\n",
      "        7.8442e-08, 1.0605e-07, 4.5941e-07, 3.2140e-07, 3.1632e-05, 3.9744e-06,\n",
      "        2.3267e-06, 2.4870e-07, 2.0849e-07, 5.6502e-05, 1.3928e-06, 2.2698e-06,\n",
      "        4.0918e-06, 2.1351e-07, 4.5094e-07, 1.2755e-08, 8.9373e-07, 1.3420e-06,\n",
      "        2.6330e-07, 1.6852e-06, 1.7183e-07, 3.6921e-07, 2.1211e-06, 1.7709e-07,\n",
      "        6.0107e-06, 1.5691e-08, 4.9418e-08, 1.8186e-07, 1.1945e-07, 1.0946e-03,\n",
      "        1.1223e-07, 5.7893e-07, 2.0163e-06, 7.7137e-05, 2.8384e-07, 1.4091e-06,\n",
      "        2.0793e-07, 3.3242e-09, 1.3641e-06, 8.7528e-07, 3.0187e-07, 4.2331e-06,\n",
      "        2.3616e-05, 5.8348e-06, 1.0683e-08, 1.5342e-08, 1.2872e-05, 4.1265e-07,\n",
      "        6.1090e-07, 1.6758e-06, 6.0323e-08, 5.5336e-07, 3.8175e-07, 1.1929e-06,\n",
      "        2.5644e-07, 1.7970e-07, 1.0763e-06, 1.1627e-06, 1.4178e-06, 7.0936e-08,\n",
      "        3.5623e-07, 9.9858e-09, 4.4604e-06, 2.2965e-07, 7.2266e-06, 2.2073e-07,\n",
      "        3.0489e-08, 5.4305e-07, 3.0426e-07, 1.7536e-07, 1.5786e-06, 3.7487e-08,\n",
      "        5.4076e-07, 6.9670e-07, 3.5375e-06, 1.4359e-06, 1.0630e-07, 3.1186e-07,\n",
      "        9.5367e-05, 6.3280e-08, 2.0414e-06, 8.4789e-07, 2.0527e-07, 2.4511e-06,\n",
      "        5.5453e-07, 6.5054e-08, 6.1753e-07, 1.0901e-07, 4.1001e-07, 4.3564e-07,\n",
      "        9.4046e-07, 2.3199e-07, 2.0216e-06, 1.0855e-07, 1.7099e-06, 3.2043e-07,\n",
      "        7.7128e-07, 1.2196e-06, 2.6579e-06, 4.1777e-08, 4.5459e-07, 6.4325e-06,\n",
      "        1.1012e-08, 2.6134e-07, 1.4898e-06, 5.7695e-07, 4.4512e-07, 6.7567e-08,\n",
      "        6.6260e-07, 4.5149e-06, 4.6138e-05, 8.4135e-07, 2.6496e-05, 6.4150e-07,\n",
      "        1.6653e-07, 4.8884e-08, 6.4193e-06, 2.6417e-08, 2.2189e-07, 3.9218e-06,\n",
      "        1.2619e-06, 5.3765e-06, 3.8935e-07, 3.5678e-06, 2.0978e-07, 2.1892e-06,\n",
      "        1.2988e-06, 1.0809e-06, 5.4701e-07, 9.5218e-07, 8.3196e-07, 1.1982e-06,\n",
      "        7.7725e-08, 1.0208e-06, 5.7314e-07, 3.7807e-08, 3.0965e-06, 1.7375e-06,\n",
      "        4.2942e-07, 9.6399e-07, 2.4592e-07, 1.3527e-07, 7.4862e-08, 4.5231e-05,\n",
      "        2.7189e-08, 2.6833e-07, 1.0245e-07, 5.3360e-07, 9.3767e-07, 4.3134e-06,\n",
      "        3.7955e-08, 1.4768e-08, 4.1824e-07, 8.4928e-08, 1.0077e-05, 2.6399e-07,\n",
      "        2.4925e-06, 2.8317e-07, 5.5343e-08, 1.7171e-07, 1.6963e-06, 4.4837e-08,\n",
      "        1.1408e-07, 3.4432e-05, 2.5529e-06, 2.1534e-08, 4.3298e-04, 1.3174e-06,\n",
      "        3.3785e-07, 6.9814e-07, 1.5378e-05, 4.1608e-06, 2.9869e-06, 1.3963e-06,\n",
      "        6.4179e-07, 4.4149e-09, 4.6880e-07, 8.6465e-08, 1.4604e-07, 1.7038e-07,\n",
      "        9.3868e-08, 6.3845e-08, 7.2309e-07, 9.0918e-08, 1.2236e-08, 1.6749e-07,\n",
      "        4.8081e-07, 1.8563e-06, 1.1717e-07, 2.8638e-06, 5.5284e-05, 1.3465e-07,\n",
      "        5.3857e-07, 1.9596e-06, 2.0432e-07, 6.3836e-09, 5.8598e-07, 6.5268e-08,\n",
      "        4.5570e-05, 2.0035e-07, 2.3035e-06, 5.3369e-06, 7.4137e-07, 9.1842e-07,\n",
      "        3.4670e-07, 1.5408e-06, 8.6330e-07, 8.9590e-08, 2.4575e-07, 3.0398e-06,\n",
      "        4.2482e-06, 3.7916e-06, 4.2254e-05, 3.2668e-06, 2.2105e-07, 1.9608e-05,\n",
      "        5.0289e-08, 1.4155e-07, 1.9895e-05, 5.3632e-06, 2.7754e-08, 4.2097e-06,\n",
      "        6.5909e-08, 2.6992e-06, 1.2293e-08, 2.1803e-07, 1.4843e-06, 9.7485e-07,\n",
      "        1.7095e-04, 4.8953e-07, 7.5165e-07, 2.2448e-06, 3.6862e-06, 6.5458e-08,\n",
      "        2.6222e-06, 6.3781e-08, 7.5147e-07, 1.5429e-06, 2.1145e-06, 2.4685e-06,\n",
      "        1.0789e-05, 4.4117e-08, 3.9812e-08, 9.7170e-06, 1.3012e-06, 8.9771e-08,\n",
      "        1.3198e-05, 9.3793e-08, 4.5473e-07, 2.3464e-07, 1.8901e-06, 4.0266e-05,\n",
      "        5.0134e-08, 2.1426e-07, 2.7952e-07, 9.6969e-06, 3.0267e-07, 4.2982e-06,\n",
      "        8.0769e-07, 7.0501e-06, 7.9626e-07, 8.7872e-08, 8.9627e-07, 4.6519e-05,\n",
      "        8.3308e-07, 3.4555e-06, 2.5292e-07, 1.8766e-07, 2.4974e-06, 3.3739e-08,\n",
      "        2.5253e-07, 1.0732e-07, 1.7034e-05, 8.2408e-06, 1.6515e-06, 4.8171e-07,\n",
      "        2.1189e-07, 1.2429e-07, 2.2962e-07, 5.1888e-06, 4.3234e-05, 2.2200e-07,\n",
      "        9.5288e-07, 8.2280e-07, 4.0088e-06, 1.0664e-07, 2.6889e-07, 2.0688e-05,\n",
      "        1.3106e-07, 4.9384e-06, 5.8443e-07, 6.7149e-08, 6.4283e-08, 6.4601e-08,\n",
      "        7.0502e-06, 1.1647e-05, 8.0278e-06, 2.4915e-07, 2.3451e-06, 2.0631e-06,\n",
      "        1.9215e-06, 2.5808e-05, 3.1167e-08, 3.7136e-06, 6.3218e-08, 2.3767e-07,\n",
      "        1.6228e-07, 1.3789e-07, 6.1056e-06, 9.5383e-08, 8.6079e-09, 1.0602e-08,\n",
      "        2.0398e-07, 4.0817e-07, 8.0534e-07, 5.0182e-07, 1.3636e-07, 3.7784e-05,\n",
      "        4.9528e-07, 4.8586e-08, 2.2339e-07, 1.3960e-05, 2.6872e-06, 3.9655e-08,\n",
      "        3.7132e-07, 1.5092e-05, 2.4550e-07, 8.3049e-07, 6.1206e-06, 1.3576e-07,\n",
      "        1.8157e-06, 2.4422e-06, 8.1634e-07, 2.4827e-06, 4.8317e-07, 1.3932e-06,\n",
      "        1.1701e-05, 5.9018e-08, 1.1966e-07, 2.0407e-06, 4.8055e-06, 4.1019e-06,\n",
      "        7.0435e-04, 8.2480e-08, 8.9414e-07, 5.5886e-05, 2.5767e-08, 1.3695e-06,\n",
      "        3.3378e-06, 8.5683e-07, 3.8504e-07, 7.1818e-06, 2.7749e-06, 2.1059e-06,\n",
      "        1.6117e-08, 6.6080e-07, 6.4732e-08, 9.3766e-08, 2.1674e-06, 1.1651e-07,\n",
      "        5.3798e-07, 4.1971e-07, 6.3069e-07, 3.0965e-07, 1.5996e-08, 1.2015e-07,\n",
      "        2.4694e-05, 1.9301e-07, 8.3228e-07, 3.9809e-06, 4.4077e-07, 1.7779e-07,\n",
      "        1.0980e-06, 6.3449e-05, 1.7790e-07, 8.3588e-06, 3.2945e-07, 1.2497e-07,\n",
      "        5.5951e-08, 1.5928e-07, 1.1494e-07, 1.2731e-07, 8.3733e-07, 1.4238e-06,\n",
      "        1.0782e-06, 2.6532e-08, 2.3269e-06, 2.6557e-06, 7.6527e-06, 2.1323e-05,\n",
      "        1.2441e-07, 8.9572e-07, 9.8838e-07, 8.5400e-07, 6.1049e-05, 4.7739e-06,\n",
      "        1.7250e-06, 4.7112e-06, 6.6934e-09, 1.1974e-06, 2.8161e-06, 1.2515e-06,\n",
      "        2.3525e-06, 7.4610e-08, 1.8926e-07, 4.4052e-08, 2.9924e-06, 1.3874e-06,\n",
      "        4.1185e-06, 1.6650e-07, 1.2142e-07, 1.6123e-06, 8.9128e-08, 1.9181e-07,\n",
      "        1.5829e-07, 2.2928e-07, 2.0610e-07, 1.6890e-07, 1.8512e-07, 6.0317e-06,\n",
      "        6.2321e-07, 4.1078e-07, 7.3626e-07, 8.2521e-08, 2.6847e-07, 3.5998e-07,\n",
      "        1.0368e-06, 3.9148e-05, 5.3315e-08, 2.8134e-06, 2.9442e-07, 2.2883e-07,\n",
      "        4.6281e-06, 5.7875e-07, 5.4496e-07, 1.2964e-07, 1.1797e-06, 7.1454e-07,\n",
      "        3.0456e-06, 3.3461e-07, 1.6937e-06, 1.7183e-06, 5.3528e-07, 1.0741e-05,\n",
      "        1.6512e-06, 1.4866e-06, 1.2405e-07, 5.4798e-07, 1.0302e-05, 1.9917e-07,\n",
      "        1.7858e-07, 3.3499e-07, 5.5178e-08, 5.3119e-08, 1.7077e-06, 8.4946e-08,\n",
      "        2.5240e-07, 1.0222e-06, 2.2912e-05, 5.2243e-06, 2.8250e-08, 2.0425e-06,\n",
      "        7.7743e-08, 1.1619e-07, 4.3785e-07, 7.4348e-07, 1.2789e-07, 7.3973e-07,\n",
      "        3.2389e-06, 2.0566e-07, 1.9036e-08, 1.6222e-07, 6.5944e-08, 1.2076e-08,\n",
      "        1.6523e-07, 5.9680e-07, 1.7601e-07, 1.3597e-04, 8.2849e-06, 7.6396e-08,\n",
      "        1.0386e-06, 3.3373e-07, 3.7533e-07, 2.6106e-07, 8.5460e-08, 2.0515e-06,\n",
      "        9.1539e-07, 2.9446e-08, 7.0169e-05, 3.5419e-06])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "filename = './images_test/cat.jpg'\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(input_image)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(input_tensor.unsqueeze(0).shape)\n",
    "\n",
    "\n",
    "input_batch = input_tensor.unsqueeze(0).to(device) # 增加一維(筆數)\n",
    "\n",
    "# 預測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "print(output.shape)\n",
    "print(output[0].shape)\n",
    "\n",
    "# change output into probabilities\n",
    "## dim (python:int): \n",
    "## A dimension along which Softmax will be computed (so every slice along dim will sum to 1).\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285: 0.6067578196525574\n"
     ]
    }
   ],
   "source": [
    "# show max class type and probability \n",
    "print(f'{torch.argmax(probabilities).item()}: {torch.max(probabilities).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egyptian cat'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示最大機率的類別名稱\n",
    "with open(\"imagenet.categories\", \"r\") as f:\n",
    "    # 取第一欄\n",
    "    categories = [s.strip().split(',')[0] for s in f.readlines()]\n",
    "categories[torch.argmax(probabilities).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 tiger: 0.9208331108093262\n"
     ]
    }
   ],
   "source": [
    "filename = './images_test/tiger2.jpg'\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0).to(device) # 增加一維(筆數)\n",
    "\n",
    "# 預測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# 轉成機率\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "max_item = torch.argmax(probabilities).item()\n",
    "print(f'{max_item} {categories[max_item]}: {torch.max(probabilities).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示最大機率的類別名稱\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    # 取第一欄\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a4022\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\a4022\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\a4022/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:10<00:00, 9.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 Egyptian cat: 0.23896856606006622\n"
     ]
    }
   ],
   "source": [
    "# 載入 resnet50 模型\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "# 預測\n",
    "filename = './images_test/cat.jpg'\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0).to(device) # 增加一維(筆數)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# 轉成機率\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "max_item = torch.argmax(probabilities).item()\n",
    "print(f'{max_item} {categories[max_item]}: {torch.max(probabilities).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data transform : Resize(256) and CenterCrop(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 tabby: 0.285623162984848\n"
     ]
    }
   ],
   "source": [
    "# 載入 resnet50 模型\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "# 預測\n",
    "filename = './images_test/cat.jpg'\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0).to(device) # 增加一維(筆數)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# 轉成機率\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "max_item = torch.argmax(probabilities).item()\n",
    "print(f'{max_item} {categories[max_item]}: {torch.max(probabilities).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabby          :  0.285623162984848\n",
      "tiger cat      :  0.2056034654378891\n",
      "lynx           :  0.1738530695438385\n",
      "Egyptian cat   :  0.16597880423069\n",
      "hamper         :  0.0126552889123559\n"
     ]
    }
   ],
   "source": [
    "# 顯示前5名\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(f'{categories[top5_catid[i]]:15s}:{\" \":2s}{top5_prob[i].item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998642460639"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(probabilities.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([281, 282, 287, 285, 588], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "probabilities.cpu().numpy().argsort()[-5:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tabby', 'tiger cat', 'lynx', 'Egyptian cat', 'hamper'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(categories)[probabilities.cpu().numpy().argsort()[-5:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 tiger: 0.9187350869178772\n"
     ]
    }
   ],
   "source": [
    "filename = './images_test/tiger2.jpg'\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0).to(device) # 增加一維(筆數)\n",
    "\n",
    "# 預測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# 轉成機率\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "max_item = torch.argmax(probabilities).item()\n",
    "print(f'{max_item} {categories[max_item]}: {torch.max(probabilities).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
